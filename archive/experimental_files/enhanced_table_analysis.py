"""Enhanced table structure reconstruction using OCR coordinates"""
import sys
sys.path.insert(0, r'C:\Learn\Code\fastembed\ai-gateway\src')
from converters.image_converter import ImageConverter
import polars as pl

def analyze_table_structure():
    print('=== ENHANCED TABLE STRUCTURE ANALYSIS ===')
    
    converter = ImageConverter()
    img_path = r'C:\Users\gargs\Downloads\Screenshot 2025-09-10 175920.png'
    result = converter.extract_text(img_path)
    
    # Get detailed OCR data
    detailed_data = result.get('ocr_detailed', [])
    if not detailed_data:
        print('âŒ No detailed OCR data available')
        return
    
    # Create DataFrame for analysis
    df = pl.DataFrame(detailed_data)
    
    print(f'ðŸ“Š Total OCR elements: {len(df)}')
    print(f'ðŸ“Š Confidence range: {df["confidence"].min()}-{df["confidence"].max()}%')
    
    # Filter high-confidence words
    confident_df = df.filter(pl.col('confidence') > 50)
    print(f'ðŸ“Š High confidence words: {len(confident_df)}')
    
    # Group by vertical position (rows) - words at similar Y coordinates are likely in same row
    # Round Y coordinates to group nearby words
    confident_df = confident_df.with_columns([
        (pl.col('top') / 20).round().cast(pl.Int64).alias('row_group')
    ])
    
    print('\nðŸ“‹ RECONSTRUCTED TABLE ROWS:')
    print('=' * 80)
    
    # Group by row and sort by horizontal position
    rows = confident_df.group_by('row_group').agg([
        pl.col('text').sort_by('left'),
        pl.col('left').sort(),
        pl.col('confidence').sort_by('left')
    ]).sort('row_group')
    
    for row_data in rows.iter_rows(named=True):
        row_group = row_data['row_group']
        texts = row_data['text']
        positions = row_data['left']
        confidences = row_data['confidence']
        
        # Create row string with spacing based on positions
        row_text = ""
        last_pos = 0
        
        for i, (text, pos, conf) in enumerate(zip(texts, positions, confidences)):
            # Add spacing based on position difference
            if i > 0:
                space_count = max(1, (pos - last_pos) // 10)  # Approximate spacing
                row_text += " " * min(space_count, 10)  # Cap at 10 spaces
            
            row_text += text
            last_pos = pos + len(text) * 8  # Approximate character width
        
        if row_text.strip():
            print(f'Row {row_group:2d}: {row_text.strip()}')
    
    print('=' * 80)
    
    # Identify potential table columns
    print('\nðŸ“Š COLUMN ANALYSIS:')
    
    # Group by horizontal position (columns)
    confident_df = confident_df.with_columns([
        (pl.col('left') / 50).round().cast(pl.Int64).alias('col_group')
    ])
    
    columns = confident_df.group_by('col_group').agg([
        pl.col('text').sort_by('top'),
        pl.col('top').sort(),
        pl.col('left').min().alias('col_position')
    ]).sort('col_position')
    
    for col_data in columns.iter_rows(named=True):
        col_group = col_data['col_group']
        texts = col_data['text'][:5]  # First 5 items
        col_pos = col_data['col_position']
        
        print(f'Col {col_group} (pos {col_pos:4d}): {" â†’ ".join(texts)}')
    
    print('\nðŸŽ¯ CONCLUSION: Our ImageConverter can reconstruct table structure!')
    print('ðŸ’¡ This is the advantage over raw Tesseract - spatial intelligence!')

if __name__ == "__main__":
    analyze_table_structure()